# 1주차

빅데이터를 지탱하는 기술

## 1장 빅데이터의 기초 지식

### 1-1 [배경] 빅데이터의 장착

- 빅데이터의 등장 배경
    - 기업들의 데이터 처리에 분산 시스템 도입 → 빅데이터 생성

- 빅데이터 취급의 어려운 점
    - 데이터 분석 방법을 모름
    - 데이터 처리에 수고와 시간이 걸림

- 빅데이터 기술의 요구
    - Hadoop: 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템
        - 초기에는 MapReduce를 참고하여 제작 → 자바 언어 프로그래밍 → 복잡함
        - 2009년 Hive 도입 → 프로그래밍 없이 데이터 집계 가능
    - NoSQL: 전통적인 RDB의 제약을 제거하는 것을 목표로 한 데이터베이스의 총칭
        - RDB보다 고속의 읽기, 쓰기 가능 & 분산 처리에 뛰어남
    
    - ‘NoSQL에 저장 → Hadoop으로 분산 처리’ 흐름 정착
        - 현실적인 비용으로 대규모 데이터 처리 실현
    
- 분산 시스템의 비즈니스 이용 개척
    - 전통적인 데이터 웨어하우스 → 하드웨어와 소프트웨어 통합 → 안정적인 성능 실현
        - 데이터 용량이 증가 → 확장성 어려움
    - 가속도적으로 늘어나는 데이터 처리 → Hadoop
    - 비교적 작고, 중요한 데이터 처리 → 데이터 웨어하우스
    - 데이터 웨어하우스와 Hadoop의 공존

- 직접 할 수 있는 데이터 분석 폭 확대
    - 클라우드 서비스 보급 → 여러 컴퓨터에 분산 처리

### 1-2 빅데이터 시대의 데이터 분석 기반

- 데이터 파이프라인
    - 일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템
- 데이터 수집
    - 벌크 형 전송: 이미 어딘가에 존재하는 데이터를 정리해 추출
    - 스트리밍 형 전송: 차례대로 생성되는 데이터를 계속해서 끊임없이 보내는 방법

- 스트림 처리와 배치 처리
    - 스트림 처리: 실시간으로 데이터를 처리
        - 지금 무슨 일이 일어나는지 바로 알 수 있음
        - 장기적인 데이터 분석에는 적합하지 않음
    - 배치 처리: 어느 정도 정리된 데이터를 효율적으로 가공하기 위한 구조

- 분산 스토리지
    - 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템

- 분산 데이터 처리
    - 분산 스토리지에 저장된 데이터를 처리
    - 나중에 분석하기 쉽도록 데이터를 가공 → 외부 DB에 저장
    - 일련의 과정을 ‘ETL 프로세스’ 라고 함

- 워크플로 관리
    - 전체 데이터 파이프라인 동작을 관리

- 데이터 웨어하우스
    - 대량의 데이터를 장기 보존하는 것에 최적화된 저장소
    - 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않음
    - 업무에 있어서 중요한 데이터 처리에 사용
- 데이터 마트
    - 데이터 웨어하우스에서 필요한 데이터만 추출하여 구성
- 데이터 레이크
    - 데이터를 원래 상태 그대로 축적하는 장소 (가공 X)
    
- 에드 혹 분석
    - 자동화 없이 수작업으로 데이터를 집계하는 방식
    - 일회성 데이터 분석이라는 의미
    - 주로 처음에 데이터를 살펴보고 싶을 때 이용
- 대시보드 도구
    - 수작업으로 그래프와 보고서를 만들 때 사용하는 도구

- 데이터 파이프라인의 큰 흐름
    - 저장할 수 있는 데이터 용량에 제한이 없을 것
    - 데이터를 효율적으로 추출할 수단이 있을 것

- 확증적 데이터 분석
    - 가설을 세우고 검증하는 분석 방식
- 탐색적 데이터 분석
    - 데이터를 보면서 의미를 파악해내는 분석 방식

- 스몰 데이터 탐색
    - 빅데이터를 탐색하기 전 준비 단계
    - 분산 시스템을 사용하지 않는 한 대의 컴퓨터로 데이터 탐색

### 1-3 스크립트 언어에 의한 특별 분석과 데이터 프레임

- 스크립트 언어
    - R, Python 사용 (Numpy, Pandas)
- 데이터 프레임
    - 표 형식의 데이터를 추상화한 객체
- 데이터 전처리에서 사용할 수 있는 Pandas 함수
    - ix: 조건에 일치하는 데이터만을 검색
    - drop: 지정한 행(칼럼)을 삭제
    - rename: 인덱스 값(칼럼명) 변경
    - dropna: 값이 없는 행(칼럼명)을 제외
    - fillna: 값이 없는 셀을 지정한 값으로 치환
    - apply: 각 칼럼(또는 행)에 함수를 적용

### 1-4 BI 도구와 모니터링

- 모니터링
    - 계획적으로 데이터의 변화를 추적해 나가는 것

- 데이터에 근거한 의사결정
    - KPI를 정기적으로 모니터링하여 의사결정
    - 어떤 행동을 결정할 때, 직감에 의지하는 것이 아닌 객관적인 데이터를 근거하여 판단하는 것

- 스프레드시트에 의한 모니터링
    - 시각화하여 보기가 어려움

- BI 도구 활용
    - 고속의 집계 엔진 내장 → 빠르게 그래프 생성
    - 원하는 대로 결과를 얻으려면, 시각화하기 쉬운 데이터를 만들어야 함

- 수작업과 자동화해야 할 것의 경계 판별
    - 수작업으로 할 수 있는 것은 수작업으로 하기
    - 자동화 해야할 경우 → 데이터 마트 만들기
        - 자주 업데이트되거나, 중요성이 높은 데이터 → 자동화

## 2장 빅데이터의 탐색

### 2-1 크로스 집계의 기본

- 크로스 테이블
    - 열 방향으로 데이터가 증가
- 트랜잭션 테이블
    - 행 방향으로 데이터가 증가
- 크로스 집계
    - 트랜잭션 테이블 → 크로스 테이블 변환 과정

- 피벗 테이블
    - 행과 열이 교차하는 부분의 값은 자동으로 집계
- 룩업 테이블
    - 테이블을 결합하여 속성을 늘림
- 크로스 집계하는 다양한 방식
    - BI 도구
    - Pandas
    - SQL
- 데이터 집계 → 데이터 마트 → 시각화
    - 데이터 마트의 크기에 따라 시스템 구성이 결정

### 2-2 열 지향 스토리지에 의한 고속화

- 데이터베이스 지연 줄이기
    - 데이터 처리의 응답이 빠르다 = 대기 시간(지연)이 적다
    - 지연 줄이기 방식 1: 가능하다면 모든 데이터를 메모리에 올리는 것
    - 지연 줄이기 방식 2: 압축 & 분산 → MPP(대규모 병렬 처리)

- 행 지향 데이터베이스(RDB)
    - 새 레코드를 추가할 때 파일에 끝에 데이터를 씀 → 빠르게 추가
    - 대량의 트랜잭션을 지연 없이 처리하기 위해 데이터 추가를 효율적으로 함
    - 데이터 양 많아질 수록 → 모든 데이터 로드 → 디스크 I/O 발생 → 성능 저하

- 열 지향 데이터베이스 접근 방식
    - 칼럼 단위로의 데이터 압축 → 필요한 칼럼만 로드 → 디스크 I/O 줄임
    - 데이터를 열 지향 스토리지 형식으로 저장 → 데이터 마트의 지연 줄임

- MPP 데이터베이스의 접근 방식
    - MPP → 하나의 쿼리를 다수의 작은 태스크로 분해(분산) → 병렬로 처리
    - CPU 코어 수의 비례하여 고속화 가능

### 2-3 애드 혹 분석과 시각화 도구

- Jupyter Notebook에 의한 애드 혹 분석
    - 오픈 소스의 대화형 도구 → 파이썬 스크립트와 외부 명령어 실행 가능
    - matplotlib 라이브러리 → 노트북에서 빠르게 시각화 가능
    - 분석 초기에 대화식으로 빠르게 처리 가능하다는 장점

- 대시보드 도구
    - 정기적으로 쿼리를 실행해 보고서를 작성하거나, 그래프를 모아서 대시보드를 작성할 때 이용
- Redsah
    - SQL에 의한 쿼리의 실행 결과를 그대로 시각화
    - BI 도구만큼 대량의 데이터는 처리 불가
- Superset
    - 대화형 대시보드를 작성하기 위한 파이썬
    - 화면 상에서 마우스 조작만으로 그래프를 만듦
    - 시계열 데이터에 대응한 열 지향 스토리지인 ‘Druid’를 표준으로 지원
    - ‘Druid’를 이용하지 않는 경우, 지연이 적은 RDB나 MPP DB 등을 조합시켜 고속화해야 함
- Kibana
    - 자바스크립트로 만들어진 대화식 시각화 도구
    - 실시간 대시보드를 만들 목적으로 자주 이용
    - Elasticsearch가 필수적

- BI 도구
    - 장기적인 데이터의 추이를 시각화하거나, 집계의 조건을 세부적으로 바꿀 수 있는 대시보드를 만들 때 이용
    - Tableau Desktop

### 2-4 데이터 마트의 기본 구조

- 시각화에 적합한 데이터 마트 만들기
    - OLAP: 데이터 집계를 효율화하는 접근 방법
    - 다차원 모델의 데이터 구조를 MDX 등의 쿼리 언어로 집계
- 테이블을 비정규화하기
    - 트랜잭션: 시간과 함께 생성되는 데이터를 기록한 것
    - 마스터: 트랜잭션에서 참고되는 각종 정보
- 팩트 테이블
    - 트랜잭션처럼 사실이 기록된 것
    - 집계의 기반이 되는 숫자 데이터
- 디멘전 테이블
    - 트랜잭션에서 참고되는 마스터 데이터 등이 기록된 것
    - 주로 데이터를 분류하기 위한 속성값으로 사용

- 스타 스키마
    - 팩트 테이블을 중심으로 여러 디멘전 테이블이 결합된 스키마 구조
    - 비정규화: 스타 스키마에서 분해된 테이블을 최대한 결합하여 하나의 테이블로 정리

- 스타 스키마가 사용되는 이유
    - 단순하여 이해하기 쉬움
    - 데이터 분석을 쉽게 할 수 있는 장점
    - 성능이 좋음
        - 데이터 양이 많아질수록 팩트 테이블 크기 커짐 → 쿼리의 지연
        - 비정규화를 통해 팩트 테이블에는 필수적인 키만 남겨두고, 나머지는 디멘전 테이블로 옮김 → 고속화

- 비정규화 테이블
    - 스타 스키마에서 좀 더 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블을 의미
    - 열 지향 스토리지는 칼럼 단위로 데이터 저장 → 칼럼 수가 늘어나도 성능 영향 x
    - 데이터 마트는 비정규화 테이블로 하는 것이 가장 단순하며, 효율적인 방법

- 다차원 모델로 추상화
    - 비정규화 테이블을 다차원 모델에 의해 추상화 → BI 도구로 시각화
    - 비정규화 테이블을 모은 것이 BI 도구를 위한 데이터 마트